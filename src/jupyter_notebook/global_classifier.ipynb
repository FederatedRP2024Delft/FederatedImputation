{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:59:18.496660400Z",
     "start_time": "2024-05-17T11:55:50.446441Z"
    }
   },
   "source": [
    "import pickle\n",
    "import torch\n",
    "from src.impute import impute_cvae_naive\n",
    "from src.vae.mnist_vae import ConditionalVae\n",
    "import numpy as np\n",
    "\n",
    "for dirichlet in np.linspace(0.1,1, 10):\n",
    "    dirichlet = round(dirichlet, 1)\n",
    "    cvae = ConditionalVae(dim_encoding=3)\n",
    "    checkpoint = torch.load(f'C:\\\\Users\\\\lyada\\\\Desktop\\\\FederatedImputation\\\\vae_data\\\\models\\\\0_cvae_{dirichlet}.pth')\n",
    "    cvae.load_state_dict(checkpoint)\n",
    "    gen_dataset = impute_cvae_naive(k=70000, trained_cvae = cvae, initial_dataset = torch.tensor([]))\n",
    "    print(gen_dataset[0][0].shape)\n",
    "    # Use pickle to save the list to a file\n",
    "    with open(f'gen_dataset_{dirichlet}.pkl', 'wb') as f:\n",
    "        pickle.dump(gen_dataset, f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from src.plots import plot_image\n",
    "loaded_gen = pickle.load(open('gen_dataset_1.0.pkl', 'rb'))\n",
    "plot_image([g for g, _ in loaded_gen], num_imgs=20)\n",
    "[print(loaded_gen[i][1]) for i in range(20)]\n",
    "len(loaded_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:51:05.481477900Z",
     "start_time": "2024-05-17T11:51:00.391477600Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# generate some random data\n",
    "labels = [label for _, label in loaded_gen]\n",
    "# Create the histogram\n",
    "plt.hist(labels, bins=10)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram (Frequency Plot)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:48:28.803293500Z",
     "start_time": "2024-05-17T11:48:28.563262100Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "lengths = [60000, 10000]\n",
    "data = pickle.load(open('gen_dataset_1.0.pkl', 'rb'))\n",
    "\n",
    "generated_train_dataset, generated_test_dataset = random_split(data, lengths)\n",
    "\n",
    "trainloader = DataLoader(generated_train_dataset,\n",
    "                                 batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(generated_test_dataset,\n",
    "                                 batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T12:03:59.749969500Z",
     "start_time": "2024-05-17T12:03:54.133972900Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.version import cuda\n",
    "from src.models import ExquisiteNetV1\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "device = 'cuda:0'\n",
    "print(device)\n",
    "# Assuming 'model' is your model\n",
    "model = ExquisiteNetV1(class_num=10, img_channels=1)\n",
    "model = model.to(device)  # Move model to GPU if available\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train the model\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "f1_scores = []\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    for data, target in trainloader:  # Assuming 'trainloader' is your DataLoader\n",
    "        data, target = data.to(device), target.to(device) # Move data to GPU if available\n",
    "\n",
    "        # Clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        pred_labels.append(output.argmax(dim=1))\n",
    "        actual_labels.append(target)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_pred_labels = []\n",
    "        test_actual_labels = []\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            test_pred_labels.append(output.argmax(dim=1))\n",
    "            test_actual_labels.append(target)\n",
    "\n",
    "    # Compute average test loss\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "    test_loss = test_loss/len(testloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    # Calculate F1 score for the test data\n",
    "    test_pred_labels = torch.cat(test_pred_labels).to('cpu').numpy()\n",
    "    test_actual_labels = torch.cat(test_actual_labels).to('cpu').numpy()\n",
    "    test_f1_score = f1_score(test_actual_labels, test_pred_labels, average='macro')\n",
    "    f1_scores.append(test_f1_score)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\t Test Loss: {:.6f} \\tF1 Test Macro: {:.6f}'.format(\n",
    "        epoch + 1,\n",
    "        train_loss,\n",
    "        test_loss,\n",
    "        test_f1_score\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T13:12:42.393155600Z",
     "start_time": "2024-05-17T13:00:28.656988500Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "plt.plot(train_losses, label = f\"train\")\n",
    "plt.plot(test_losses, label = f\"test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f1_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T13:14:32.044366600Z",
     "start_time": "2024-05-17T13:14:31.907943400Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "plt.plot(f1_scores, label = f\"f1\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T13:14:38.685376200Z",
     "start_time": "2024-05-17T13:14:38.553520800Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
